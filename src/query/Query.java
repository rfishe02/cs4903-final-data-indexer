
//package src.main.java;

/********************************
Name: Renae Fisher
Username: text05
Problem Set: PS3
Due Date: 7/15/19
********************************/

import java.io.*;
import java.util.HashMap;
import java.util.HashSet;
import java.util.PriorityQueue;
import java.util.Comparator;
import java.util.ArrayList;
import java.util.Iterator;
import java.util.Map;
import java.nio.charset.*;

/** The class UAQuery, a non-executable class, is executed by the web interface and the UAQueryTest class. */

public class Query {
  String NA;
  int size;
  int STR_LEN;
  int MAP_LEN;
  int DICT_LEN;
  int POST_LEN;
  int seed;

  int limit = 12;

  /** The consructor for the UAQuery class opens a RandomAccessFile with statistical information,
  and uses it to load the parameters needed to run the application.
  @param rafDir A directory of random access files generated by the UAInvertedIndex class.
  @param filename The name of the RandomAccessFile that holds information about the files created by UAInvertedIndex.
  */

  public Query(File rafDir, String filename) {

    try {
        RandomAccessFile stat = new RandomAccessFile(rafDir.getPath()+"/"+filename,"r");
        stat.seek(0);
        NA = stat.readUTF();
        size = stat.readInt();
        STR_LEN = stat.readInt();
        MAP_LEN = stat.readInt();
        DICT_LEN = STR_LEN + (stat.readInt() * 4);
        POST_LEN = stat.readInt() * 4;
        seed = stat.readInt();
        stat.close();

    } catch(IOException ex) {
        ex.printStackTrace();
        System.exit(1);
    }
  }

  /** Calls the methods needed to facilitate a search.
  @param inDir The directory of tokenized files that UAInvertedIndex used to build the inverted index.
  @param rafDir A directory of random access files generated by the UAInvertedIndex class.
  @param query An array of words that the engine will use to conduct a search.
  @return A list of the top k documents, along with the document IDs and cosine similarity scores.
  */

  public String[] runQuery(File inDir, File rafDir, String[] query) {
    String[] result = null;

    try {
      HashMap<Integer,Integer> docMap = new HashMap<Integer,Integer>(100000);
      HashMap<String,Integer> termMap = new HashMap<String,Integer>(10000000);
      HashMap<String,Integer> qMap = new HashMap<String,Integer>(50);

      PriorityQueue<Term> pq = getQueue(rafDir, qMap, query); // Create a priority queue that ranks documents by count.
      File[] list = getIntersect(rafDir, inDir, docMap, pq); // Get a subset of files, an intersection between sets.

      if(list.length > 0 && list[0] != null) {

        mapTerms(list,termMap); // Map terms to rows.

        float[][] tdm = buildTDM(rafDir,termMap,docMap,qMap,Math.min(query.length,limit)); // Build a term-document matrix to find the k most relevant documents.
        list = getDocs(inDir,rafDir,docMap,tdm,10); // Get the k most relevant documents.

        // We may build the term-context matrix at this point. -----------------

        Semantic s = new Semantic();
        HashMap<String,Integer> vocab = s.getVocab(list);
        float[][] tcm = s.buildTermContextMatrix(list,vocab,vocab.size(),4);
        result = s.getContext(vocab,tcm,5,vocab.get("cat")); // Testing in memory query.

        //----------------------------------------------------------------------

      } else {
        System.out.println("no results found.");
      }

    } catch(IOException ex) {
      ex.printStackTrace();
      System.exit(1);
    }

    return result;
  }

  /** Create a queue of all terms, ranked by their number of documents.
      It's used to find the smallest subset. This also gets statistics about the query.
  */

  public PriorityQueue<Term> getQueue(File rafDir, HashMap<String,Integer> qMap, String[] query) throws IOException {
    RandomAccessFile dict = new RandomAccessFile(rafDir.getPath()+"/dict.raf","r");
    PriorityQueue<Term> pq = new PriorityQueue<>( new TermComparator() );
    String record;
    int i;
    int count;
    int start;

    for(int a = 0; a < query.length; a++) {

      if(qMap.containsKey(query[a])) {
        qMap.put(query[a],qMap.get(query[a])+1);
      } else {
        qMap.put(query[a],1);
      }  // Count the frequency of terms in the query.

      i = 0;  // Find the term in the dictionary.
      do {
        dict.seek( hash(query[a],i,seed) * (DICT_LEN + 2) );
        record = dict.readUTF();
        i++;
      } while( i < seed && record.trim().compareToIgnoreCase(NA) != 0 && record.trim().compareToIgnoreCase(query[a]) != 0);

      if( record.trim().compareToIgnoreCase(NA) != 0 && record.trim().compareToIgnoreCase(query[a]) == 0 ) {
        count = dict.readInt();
        start = dict.readInt();
        pq.add( new Term(query[a],count,start) ); // Order terms by number of documents.
      }

    }

    dict.close();
    return pq;
  }

  /** Find the files that all terms have in common. Starting with the smallest subset, it counts the frequencies of documents for each term.
      It returns an array of the most frequent documents (those that appear among all terms). This also maps documents to columns.
   */

  public File[] getIntersect(File rafDir, File inDir, HashMap<Integer,Integer> docMap, PriorityQueue<Term> pq) throws IOException {
    RandomAccessFile post = new RandomAccessFile(rafDir.getPath()+"/post.raf","r");
    RandomAccessFile map = new RandomAccessFile(rafDir.getPath()+"/map.raf","r");
    HashMap<Integer,Integer> intersect = new HashMap<>();
    Term query;
    float rtfIDF;
    int docID;
    int size;
    int col = 1;

    size = pq.size();

    while(!pq.isEmpty()) {
      query = pq.remove();

      post.seek( query.start * POST_LEN );
      for(int x = 0; x < query.count; x++) {

        docID = post.readInt();
        rtfIDF = post.readFloat();

        if(rtfIDF > 0.0001) {
          if(intersect.containsKey(docID)) {
            intersect.put(docID,intersect.get(docID)+1); // Count the number of times we see the document.
          } else {
            intersect.put(docID,1);
          }
        } // Choose documents with high scores.

      } // Read each posting for the term.

    } // Find an intersection of documents.

    File[] result = new File[intersect.size()];
    int x = 0;
    for (Map.Entry<Integer,Integer> entry : intersect.entrySet()) {
      if(entry.getValue() >= size) {

        map.seek(entry.getKey() * (MAP_LEN + 2));
        result[x] = new File(inDir.getPath()+"/"+(map.readUTF()).trim());
        x++;

        if(!docMap.containsKey(entry.getKey())) {
          docMap.put(entry.getKey(),col);
          col++;
        } // Map documents to cols.

      }
    }

    post.close();
    map.close();
    return result;
  }

  /** Uses the query array and random access files to map terms and document IDs to rows and columns.
  This information will be used to build the term document matrix.
  @param inDir The directory of tokenized files that UAInvertedIndex used to build the inverted index.
  @param rafDir A directory of random access files generated by the UAInvertedIndex class.
  @param termMap A hash table that maps terms to rows in the term document matrix.
  @param docMap A hash table that maps document IDs to columns in the term document matrix.
  @param q A hash table that will contain all distinct words in the query and their frequencies.
  @param query A query as an array of words.
  */

  public void mapTerms(File[] files, HashMap<String,Integer> termMap) throws IOException {
    BufferedReader br;
    String read;
    int row = 0;

    System.out.println("mapping terms to rows.");

    for(int i = 0; i < files.length; i++) {

      if(files[i] != null) {
        br = new BufferedReader( new FileReader(files[i]) );

        while((read=br.readLine())!=null) {
          if(!termMap.containsKey(read)) {
            termMap.put(read,row);
            row++;
          }
        } // Open file & map terms within to columns.
      }

    }
  }

  /** The same hash function used to construct the global hash table.
  @param str A term of interest.
  @param i An index.
  @param n The size of the hash table.
  @return A hashcode for a given String.
  */

  public int hash(String str, int i, int n) {
    return ( Math.abs(str.hashCode()) + i ) % n;
  } // h(k,i) = (h'(k) + i) mod m

  /** */

  static class TermComparator implements Comparator<Term> {
    public int compare(Term o1, Term o2) {
      if(o1.count > o2.count) {
        return 1;
      } else if(o1.count < o2.count) {
        return -1;
      } else {
        return 0;
      }
    }
  }

  /** A function used to normalize a String, which uses the same techniques used in the
  tokenization phase. It iterates over characters and converts non-ASCII characters to a
  one byte character.
  @param s An input String.
  @param limit The desired length of a the resulting String.
  @return A normalized String.
  */

  /* Substitute this method with the Tokenizer used to create the tokens for this project.
    (Create a method that could accept the String and return a list.)
  */

  public String convertText(String s, int limit) {
    String out = "";
    int len;

    len = Math.min(s.length(),limit);

    for(int i = 0; i < len; i++) {
        if((int)s.charAt(i) > 127) {
            out += "?";
        } else if ( (int)s.charAt(i) > 47 && (int)s.charAt(i) < 58 ||
            (int)s.charAt(i) > 96 && (int)s.charAt(i) < 123 ) {
            out += s.charAt(i);
        } else if( (int)s.charAt(i) > 64 && (int)s.charAt(i) < 91 ) {
            out += (char)((int)s.charAt(i) + 32);
        }
    }

    if(out.length() > 7) {
      out = out.substring(0,8);
    }

    return out;
  }

  //============================================================================
  // UNUSED METHODS
  //============================================================================

  /** A class used as the Comparator for the PriorityQueue in the getDocs method. */

  static class ResultComparator implements Comparator<Result> {
    public int compare(Result s1, Result s2) {
      if(s1.score > s2.score) {
        return -1;
      } else if(s1.score < s2.score) {
        return 1;
      } else {
        return 0;        }
    }
  }

  /** A class that stores results for the getDocs method. */

  static class Result {
    String name;
    float score;
    int id;

    public Result(String name, int id, float score) {
      this.name = name;
      this.id = id;
      this.score = score;
    }
  }

  /** Uses hash tables, with term and document mappings, to construct the term document matrix.
  @param rafDir A directory of random access files generated by the UAInvertedIndex class.
  @param termMap A hash table that maps terms to rows in the term document matrix.
  @param docMap A hash table that maps document IDs to columns in the term document matrix.
  @param query A hash table that will contain all distinct words in the query and their frequencies.
  @return A complete term-document matrix.
  */

  public float[][] buildTDM(File rafDir, HashMap<String,Integer> termMap, HashMap<Integer,Integer> docMap, HashMap<String,Integer> query, int qSize) throws IOException {
    RandomAccessFile dict = new RandomAccessFile(rafDir.getPath()+"/dict.raf","r");
    RandomAccessFile post = new RandomAccessFile(rafDir.getPath()+"/post.raf","r");
    float[][] tdm = new float[termMap.size()][docMap.size()+1]; // Add the query column.
    String record = NA;
    float rtfIDF;
    int count;
    int start;
    int docID = 0;
    int i;

    System.out.println("building the term document matrix of "+termMap.size()+" x "+docMap.size()+" size");

    for( Map.Entry<String,Integer> entry : termMap.entrySet() ) {

      i = 0;
      do {
        dict.seek( hash(entry.getKey(),i,seed) * (DICT_LEN + 2) );
        record = dict.readUTF();
        i++;

      } while( i < seed && record.trim().compareToIgnoreCase(NA) != 0 && record.trim().compareToIgnoreCase(entry.getKey()) != 0);

      if(record.trim().compareToIgnoreCase(NA) != 0 && record.trim().compareToIgnoreCase(entry.getKey()) == 0) {

        count = dict.readInt();
        start = dict.readInt();

        System.out.println(count);

        post.seek( start * POST_LEN );
        for(int x = 0; x < count; x++) {
          docID = post.readInt(); // Acquire document IDs.
          rtfIDF = post.readFloat();

          if(docMap.containsKey(docID)) {
            tdm[ entry.getValue() ][ docMap.get(docID) ] = rtfIDF;
          }
        } // Read each posting for the term.

        if( query.containsKey( entry.getKey() ) ) {
          tdm[ entry.getValue() ][ 0 ] = (float) ( ( (double)query.get(entry.getKey()) / qSize ) * Math.log( size / count ) ); // Calculates RTF-IDF for the query.
        }

      }

    }
    dict.close();
    post.close();

    return tdm;
  }

  /** The method that finds the top k documents for a given query. It iterates over the documents in the docMap,
  and calculates cosine similarity between each document and the query.
  @param rafDir A directory of random access files generated by the UAInvertedIndex class.
  @param docMap A hash table that maps document IDs to columns in the term document matrix.
  @param tdm A complete term document matrix.
  @param k The number of documents desired for the result.
  @return A list of the top k documents with the greatest cosine similarity for a given query.
  */

  public File[] getDocs(File inDir, File rafDir, HashMap<Integer,Integer> docMap, float[][] tdm, int k) throws IOException {
    RandomAccessFile map = new RandomAccessFile(rafDir.getPath()+"/map.raf","r");
    PriorityQueue<Result> pq = new PriorityQueue<Result>( new ResultComparator() );
    File[] res = new File[k];

    System.out.println("finding relevant documents.");

    for( Map.Entry<Integer,Integer> entry : docMap.entrySet() ) {
      map.seek( entry.getKey() * (MAP_LEN + 2) );
      pq.add( new Result( map.readUTF(), entry.getKey(), calcCosineSim(tdm,entry.getValue(),0) ) );
    }

    Result r;
    int j = 0;
    while(j < k && !pq.isEmpty()) {
      r = pq.remove();
      res[j] = new File(inDir.getPath()+"/"+r.name);
      //System.out.println(r.name+" "+r.id+" "+r.score);
      j++;
    }

    map.close();
    return res;
  }

  /** The method that finds cosine similarity between two columns in the term-document matrix.
  @param tdm A complete term document matrix.
  @param d A column of interest in a term document matrix.
  @param q The query column.
  @return Cosine similarity for two columns of interest.
  */

  public float calcCosineSim(float[][] tdm, int d, int q) {
    double one = 0.0;
    double two = 0.0;
    double tot = 0.0;

    for(int i = 0; i < tdm.length; i++) {
      tot += ( tdm[i][d] * tdm[i][q] );
      one += Math.pow( tdm[i][d],2 );
      two += Math.pow( tdm[i][q],2 );
    }

    return (float)( (tot) / (Math.sqrt(one) * Math.sqrt(two)) );
  }


    /*
    public static String convertText(String s, int limit) {
      String out = "";
      int len;

      len = Math.min(s.length(),limit);

      for(int i = 0; i < len; i++) {
          if((int)s.charAt(i) > 127) {
              out += "?";
          } else if ( (int)s.charAt(i) > 47 && (int)s.charAt(i) < 58 ||
              (int)s.charAt(i) > 96 && (int)s.charAt(i) < 123 ) {
              out += s.charAt(i);
          } else if( (int)s.charAt(i) > 64 && (int)s.charAt(i) < 91 ) {
              out += (char)((int)s.charAt(i) + 32);
          }
      }

      if(out.length() > 7) {
        out = out.substring(0,8);
      }

      return out;
    }*/

}
